* Sitemap generation for school domains

** Description
      The input is a domain name, develop a crawler which identifies the URL and sub URL and creates a site map. 
      Connected report: for each URL what pages are backlinking to the respected URL.

** Output format
      #+BEGIN_SRC json
      {
            "domain": "https://www.princetonk12.org/",
            "schoolName": "Princeton Public School",
            "text/content" : "---",
            "siteMapData": {
            "0": {
                  "Level": 0
                  "pageName" : "Homepage",
                  "link" : "/index.html",
                  "text/content" : "---",
                  "backlinkInfo": { "--" : "--" },
            },
            "1": {
                  "Level": 1
                  "pageName" : "About Us",
                  "link" : "/about-us",
                  "text/content" : "---",
                  "backlinkInfo": { "--" : "--" },
            },
            "2": {
                  "Level": 2
                  "pageName" : "The New School Year",
                  "link" : "/district/the-new-school-year",
                  "text/content" : "---",
                  "backlinkInfo": { "--" : "--" },
            },
            ---
            ---
            },
            "alexaAPIdata": {
                  "UrlInfo" : {},
                  "TrafficHistory" : {},
                  "SitesLinkingIn" : {},
            },
            "linkedinAPIdata": {
                  "name": "--",
                  "city": "--",
                  "state": "--",
                  "locations": []
            }
      }
      #+END_SRC

** Roadmap
      1. Getting backlinks for generated sitemaps [80%] -> 4 days
            - [X] *Logging module* (How to disable logging on sitemap_gen, set
              logging file)
            - [X] *Tests module*
            - [X] *Sitemap generator module*
            - [X] Use threading for parallel processing
            - [X] Read config.json for runtime options
            - [X] argv[1] of single url
            - [-] *XML conversor module*
            - [-] Xml to json conversion

           

            - [X] Read from input file
            - [X] Blacklink info?

      2. Alexa API integration [80%] -> 3 days
            - [X] *Curl http request module*
            - [X] *UrlInfo: generate request*
            - [X] TrafficHistory: generate request
            - [X] SitesLinkingIn: generate request
            - [-] Xml to json conversion

           

      3. LinkedIn API integration [100%] -> 3 days
           - [X] *LinkedIn Module*
           - [X] Create a search filter for the organization name
           - [X] Retrieve city from linkedin API
           - [X] Retrieve state from linkedin API

           

      4. REST API [0%] --> thats an extra ~ 2 days ???
            - [X] Accept a list of url's as request
            - [X] Respond dynamoDb proper Json object

** Architeture

      config.json
      main.py
      requirements.txt
      test.py
      modules/
       modules/alexa.py
       modules/linkedin.py
       modules/sitemapGen.py
       modules/xml2json.py

#+BEGIN_SRC dot

digraph G {

	graph [layout=dot rankdir=LR]
	main[shape=box]
	xml2json[shape=box]
      {url, config} -> main -> {sitemapGen, alexaAPI,  linkedinAPI} -> xml2json -> dynamoDb
	
}

#+END_SRC

